{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4c8ab07e5b8de",
   "metadata": {},
   "source": [
    "# NB Algorithma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de772168b75fa7",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T11:48:15.347885Z",
     "start_time": "2024-12-12T11:48:14.567287Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5e40432363a9e",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5e2ff64558c03492",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T11:48:16.618817Z",
     "start_time": "2024-12-12T11:48:15.367525Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_from_folder(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    combined_df = df_list[0]\n",
    "    \n",
    "    for df in df_list[1:]:\n",
    "        combined_df = pd.merge(combined_df, df, on='id', how='outer')\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "test_folder = '../data/test/'\n",
    "test_df = load_data_from_folder(test_folder)\n",
    "\n",
    "train_folder = '../data/train/'\n",
    "train_df = load_data_from_folder(train_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ddb184b4dacfba",
   "metadata": {},
   "source": [
    "### NB Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "73f2e7986f6ba54c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T11:48:17.907914Z",
     "start_time": "2024-12-12T11:48:17.535046Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImprovedNaiveBayes(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, feature_selection_threshold=0.01, smoothing=1e-10):\n",
    "        self.classes_ = None \n",
    "        self.class_probabilities = {}\n",
    "        self.feature_probabilities = {}\n",
    "        self.feature_weights = None\n",
    "        self.feature_selection_threshold = feature_selection_threshold\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def feature_selection(self, X, y):\n",
    "        mi_scores = mutual_info_classif(X, y)\n",
    "        selected_features = mi_scores > self.feature_selection_threshold\n",
    "        return selected_features\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        selected_features = self.feature_selection(X, y)\n",
    "        X = X[:, selected_features]\n",
    "        \n",
    "        self.feature_weights = selected_features\n",
    "        self.classes_ = np.unique(y)  \n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        for cls in self.classes_:\n",
    "            self.class_probabilities[cls] = np.sum(y == cls) / n_samples\n",
    "        \n",
    "        self.feature_probabilities = {}\n",
    "        \n",
    "        for cls in self.classes_:\n",
    "            X_cls = X[y == cls]\n",
    "            cls_feature_probs = []\n",
    "            for feature_idx in range(n_features):\n",
    "                feature_values = X_cls[:, feature_idx]\n",
    "                unique_vals, counts = np.unique(feature_values, return_counts=True)\n",
    "                \n",
    "                prob_dict = {val: (count + self.smoothing) / (len(feature_values) + self.smoothing * len(unique_vals)) \n",
    "                             for val, count in zip(unique_vals, counts)}\n",
    "                cls_feature_probs.append(prob_dict)\n",
    "            \n",
    "            self.feature_probabilities[cls] = cls_feature_probs\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        \n",
    "        if self.feature_weights is not None:\n",
    "            X = X[:, self.feature_weights]\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for sample in X:\n",
    "            class_scores = {}\n",
    "            \n",
    "            for cls in self.classes_:\n",
    "                score = np.log(self.class_probabilities[cls])\n",
    "                \n",
    "                for feature_idx, feature_val in enumerate(sample):\n",
    "                    feature_prob = self.feature_probabilities[cls][feature_idx].get(feature_val, self.smoothing)\n",
    "                    score += np.log(feature_prob)\n",
    "                \n",
    "                class_scores[cls] = score\n",
    "            \n",
    "            predictions.append(max(class_scores, key=class_scores.get))\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"feature_selection_threshold\": self.feature_selection_threshold, \"smoothing\": self.smoothing}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "        print(f\"Model saved in {filename}.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(filename):\n",
    "        with open(filename, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"Model loaded from {filename}.\")\n",
    "        return model\n",
    "    \n",
    "    def submit(self, X, output_filename=\"predictions.csv\"):\n",
    "        predictions = self.predict(X)\n",
    "        \n",
    "        prediction_df = pd.DataFrame({\n",
    "            'id': range(len(predictions)),\n",
    "            'attack_cat': predictions\n",
    "        })\n",
    "        \n",
    "        prediction_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Predictions saved to {output_filename}.\")\n",
    "        \n",
    "        return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "735c725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, test_size=0.3, random_state=42):\n",
    "    X = train_df.drop(['attack_cat', 'label'], axis=1)\n",
    "    y = train_df['attack_cat']\n",
    "    \n",
    "    numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "    categorical_columns = X.select_dtypes(exclude=['number']).columns\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        X[col] = X[col].fillna(X[col].mean())\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        X[col] = X[col].fillna(X[col].mode()[0])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    y_encoded = y\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=test_size, stratify=y_encoded, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler, label_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ab7bc96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_test_data(test_df, scaler, label_encoders):\n",
    "    X_test = test_df.copy()\n",
    "    \n",
    "    numeric_columns = X_test.select_dtypes(include=['number']).columns\n",
    "    categorical_columns = X_test.select_dtypes(exclude=['number']).columns\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        X_test[col] = X_test[col].fillna(X_test[col].mean())\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        X_test[col] = X_test[col].fillna(X_test[col].mode()[0])\n",
    "\n",
    "    X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        if col in label_encoders:\n",
    "            le = label_encoders[col]\n",
    "            if 'unknown' not in le.classes_:\n",
    "                le.classes_ = np.append(le.classes_, 'unknown')\n",
    "            \n",
    "            X_test[col] = X_test[col].apply(lambda x: x if x in le.classes_ else 'unknown')\n",
    "            X_test[col] = le.transform(X_test[col])\n",
    "            print(f\"Encoded categorical column: {col}\")\n",
    "    \n",
    "    return X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "50aaede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in naive_bayes_model.pkl.\n",
      "\n",
      "Cross-Validation Accuracy (Mean): 74.88%\n",
      "Cross-Validation Accuracy (Standard Deviation): 0.32%\n",
      "\n",
      "Cross-Validation Accuracy (Mean): 64.65%\n",
      "Cross-Validation Accuracy (Standard Deviation): 0.19%\n",
      "\n",
      "Naive Bayes kustom classification accuracy: 75.00%\n",
      "\n",
      "Detailed Classification Report (Custom Naive Bayes):\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.57      0.18      0.27       600\n",
      "      Backdoor       0.04      0.20      0.07       524\n",
      "           DoS       0.31      0.61      0.41      3679\n",
      "      Exploits       0.74      0.53      0.62     10018\n",
      "       Fuzzers       0.59      0.68      0.63      5455\n",
      "       Generic       0.98      0.98      0.98     12000\n",
      "        Normal       0.98      0.82      0.89     16800\n",
      "Reconnaissance       0.82      0.71      0.76      3148\n",
      "     Shellcode       0.64      0.68      0.66       340\n",
      "         Worms       0.35      0.64      0.45        39\n",
      "\n",
      "      accuracy                           0.75     52603\n",
      "     macro avg       0.60      0.60      0.57     52603\n",
      "  weighted avg       0.82      0.75      0.77     52603\n",
      "\n",
      "\n",
      "Naive Bayes from sklearn classification accuracy: 64.39%\n",
      "\n",
      "Detailed Classification Report (sklearn Naive Bayes):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\preda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.00      0.00      0.00       600\n",
      "      Backdoor       0.00      0.00      0.00       524\n",
      "           DoS       0.24      0.77      0.36      3679\n",
      "      Exploits       0.67      0.39      0.49     10018\n",
      "       Fuzzers       0.40      0.56      0.47      5455\n",
      "       Generic       0.92      0.96      0.94     12000\n",
      "        Normal       0.95      0.74      0.83     16800\n",
      "Reconnaissance       0.55      0.01      0.01      3148\n",
      "     Shellcode       0.00      0.00      0.00       340\n",
      "         Worms       0.02      0.62      0.03        39\n",
      "\n",
      "      accuracy                           0.64     52603\n",
      "     macro avg       0.37      0.40      0.31     52603\n",
      "  weighted avg       0.73      0.64      0.65     52603\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\preda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\preda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(X_train, y_train, model, cv_folds=5):\n",
    "    kfold = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cross_val_scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    \n",
    "    print(f\"\\nCross-Validation Accuracy (Mean): {cross_val_scores.mean() * 100:.2f}%\")\n",
    "    print(f\"Cross-Validation Accuracy (Standard Deviation): {cross_val_scores.std() * 100:.2f}%\")\n",
    "    \n",
    "    return cross_val_scores.mean()\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler, label_encoders = preprocess_data(train_df)\n",
    "\n",
    "nb = ImprovedNaiveBayes(feature_selection_threshold=0.01)\n",
    "nb.fit(X_train, y_train)\n",
    "nb.save_model('naive_bayes_model.pkl')\n",
    "# prediction_df = nb.submit(X_test, output_filename=\"predictions.csv\")\n",
    "\n",
    "evaluate_model(X_train, y_train, nb, cv_folds=5)\n",
    "\n",
    "predictions = nb.predict(X_test)\n",
    "\n",
    "nb_sklearn = BernoulliNB()\n",
    "nb_sklearn.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(X_train, y_train, nb_sklearn, cv_folds=5)\n",
    "\n",
    "predictions_sklearn = nb_sklearn.predict(X_test)\n",
    "\n",
    "accuracy_custom = accuracy_score(y_test, predictions)\n",
    "print(f\"\\nNaive Bayes kustom classification accuracy: {accuracy_custom * 100:.2f}%\")\n",
    "print(\"\\nDetailed Classification Report (Custom Naive Bayes):\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "accuracy_sklearn = accuracy_score(y_test, predictions_sklearn)\n",
    "print(f\"\\nNaive Bayes from sklearn classification accuracy: {accuracy_sklearn * 100:.2f}%\")\n",
    "print(\"\\nDetailed Classification Report (sklearn Naive Bayes):\")\n",
    "print(classification_report(y_test, predictions_sklearn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a47959d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from naive_bayes_model.pkl.\n",
      "Encoded categorical column: state\n",
      "Encoded categorical column: service\n",
      "Encoded categorical column: proto\n",
      "Predictions saved to predictions.csv.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = ImprovedNaiveBayes.load_model('naive_bayes_model.pkl')\n",
    "X_test_processed = preprocess_test_data(test_df, scaler, label_encoders)\n",
    "prediction_df = loaded_model.submit(X_test_processed, output_filename=\"predictions.csv\")\n",
    "\n",
    "# Gunakan model yang dimuat untuk prediksi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predictionss = loaded_model.predict(X_test)\n",
    "# accuracy_custom = accuracy_score(y_test, predictionss)\n",
    "# print(f\"\\nNaive Bayes kustom classification accuracy: {accuracy_custom * 100:.2f}%\")\n",
    "# print(\"\\nDetailed Classification Report (Custom Naive Bayes):\")\n",
    "# print(classification_report(y_test, predictionss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
