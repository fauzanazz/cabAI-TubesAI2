{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4c8ab07e5b8de",
   "metadata": {},
   "source": [
    "# NB Algorithma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de772168b75fa7",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T11:48:15.347885Z",
     "start_time": "2024-12-12T11:48:14.567287Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5e40432363a9e",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e2ff64558c03492",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T11:48:16.618817Z",
     "start_time": "2024-12-12T11:48:15.367525Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_folder = '../data/test/'\n",
    "test_files = os.listdir(test_folder)\n",
    "test_df = pd.DataFrame()\n",
    "for file in test_files:\n",
    "    df = pd.read_csv(test_folder + file)\n",
    "    test_df = pd.concat([test_df, df], axis=1)\n",
    "\n",
    "# Load train data\n",
    "train_folder = '../data/train/'\n",
    "train_files = os.listdir(train_folder)\n",
    "train_df = pd.DataFrame()\n",
    "for file in train_files:\n",
    "    df = pd.read_csv(train_folder + file)\n",
    "    train_df = pd.concat([train_df, df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ddb184b4dacfba",
   "metadata": {},
   "source": [
    "### NB Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73f2e7986f6ba54c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T11:48:17.907914Z",
     "start_time": "2024-12-12T11:48:17.535046Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImprovedNaiveBayes(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, feature_selection_threshold=0.01, smoothing=1e-10):\n",
    "        self.classes_ = None \n",
    "        self.class_probabilities = {}\n",
    "        self.feature_probabilities = {}\n",
    "        self.feature_weights = None\n",
    "        self.feature_selection_threshold = feature_selection_threshold\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def feature_selection(self, X, y):\n",
    "        mi_scores = mutual_info_classif(X, y)\n",
    "        selected_features = mi_scores > self.feature_selection_threshold\n",
    "        return selected_features\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        selected_features = self.feature_selection(X, y)\n",
    "        X = X[:, selected_features]\n",
    "        \n",
    "        self.feature_weights = selected_features\n",
    "        self.classes_ = np.unique(y)  \n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        for cls in self.classes_:\n",
    "            self.class_probabilities[cls] = np.sum(y == cls) / n_samples\n",
    "        \n",
    "        self.feature_probabilities = {}\n",
    "        \n",
    "        for cls in self.classes_:\n",
    "            X_cls = X[y == cls]\n",
    "            cls_feature_probs = []\n",
    "            for feature_idx in range(n_features):\n",
    "                feature_values = X_cls[:, feature_idx]\n",
    "                unique_vals, counts = np.unique(feature_values, return_counts=True)\n",
    "                \n",
    "                prob_dict = {val: (count + self.smoothing) / (len(feature_values) + self.smoothing * len(unique_vals)) \n",
    "                             for val, count in zip(unique_vals, counts)}\n",
    "                cls_feature_probs.append(prob_dict)\n",
    "            \n",
    "            self.feature_probabilities[cls] = cls_feature_probs\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        \n",
    "        if self.feature_weights is not None:\n",
    "            X = X[:, self.feature_weights]\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for sample in X:\n",
    "            class_scores = {}\n",
    "            \n",
    "            for cls in self.classes_:\n",
    "                score = np.log(self.class_probabilities[cls])\n",
    "                \n",
    "                for feature_idx, feature_val in enumerate(sample):\n",
    "                    feature_prob = self.feature_probabilities[cls][feature_idx].get(feature_val, self.smoothing)\n",
    "                    score += np.log(feature_prob)\n",
    "                \n",
    "                class_scores[cls] = score\n",
    "            \n",
    "            predictions.append(max(class_scores, key=class_scores.get))\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"feature_selection_threshold\": self.feature_selection_threshold, \"smoothing\": self.smoothing}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "735c725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, test_size=0.3, random_state=42):\n",
    "    X = train_df.drop('attack_cat', axis=1)\n",
    "    y = train_df['attack_cat']\n",
    "    \n",
    "    numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "    categorical_columns = X.select_dtypes(exclude=['number']).columns\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        X[col] = X[col].fillna(X[col].mode()[0])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_columns:\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "    \n",
    "    y_encoded = y\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=test_size, stratify=y_encoded, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50aaede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Accuracy (Mean): 79.93%\n",
      "Cross-Validation Accuracy (Standard Deviation): 0.25%\n",
      "\n",
      "Cross-Validation Accuracy (Mean): 70.77%\n",
      "Cross-Validation Accuracy (Standard Deviation): 0.21%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(X_train, y_train, model, cv_folds=5):\n",
    "    kfold = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cross_val_scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    \n",
    "    print(f\"\\nCross-Validation Accuracy (Mean): {cross_val_scores.mean() * 100:.2f}%\")\n",
    "    print(f\"Cross-Validation Accuracy (Standard Deviation): {cross_val_scores.std() * 100:.2f}%\")\n",
    "    \n",
    "    return cross_val_scores.mean()\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_data(train_df)\n",
    "\n",
    "nb = ImprovedNaiveBayes(feature_selection_threshold=0.01)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# evaluate_model(X_train, y_train, nb, cv_folds=5)\n",
    "\n",
    "predictions = nb.predict(X_test)\n",
    "\n",
    "nb_sklearn = BernoulliNB()\n",
    "nb_sklearn.fit(X_train, y_train)\n",
    "\n",
    "# evaluate_model(X_train, y_train, nb_sklearn, cv_folds=5)\n",
    "\n",
    "predictions_sklearn = nb_sklearn.predict(X_test)\n",
    "\n",
    "accuracy_custom = accuracy_score(y_test, predictions)\n",
    "print(f\"\\nNaive Bayes kustom classification accuracy: {accuracy_custom * 100:.2f}%\")\n",
    "print(\"\\nDetailed Classification Report (Custom Naive Bayes):\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "accuracy_sklearn = accuracy_score(y_test, predictions_sklearn)\n",
    "print(f\"\\nNaive Bayes from sklearn classification accuracy: {accuracy_sklearn * 100:.2f}%\")\n",
    "print(\"\\nDetailed Classification Report (sklearn Naive Bayes):\")\n",
    "print(classification_report(y_test, predictions_sklearn))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
