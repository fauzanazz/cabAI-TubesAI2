{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4c8ab07e5b8de",
   "metadata": {},
   "source": [
    "# NB Algorithma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de772168b75fa7",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T11:48:15.347885Z",
     "start_time": "2024-12-12T11:48:14.567287Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5e40432363a9e",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e2ff64558c03492",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T11:48:16.618817Z",
     "start_time": "2024-12-12T11:48:15.367525Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_from_folder(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    combined_df = df_list[0]\n",
    "    \n",
    "    for df in df_list[1:]:\n",
    "        combined_df = pd.merge(combined_df, df, on='id', how='outer')\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "test_folder = '../data/test/'\n",
    "test_df = load_data_from_folder(test_folder)\n",
    "\n",
    "train_folder = '../data/train/'\n",
    "train_df = load_data_from_folder(train_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ddb184b4dacfba",
   "metadata": {},
   "source": [
    "### NB Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f2e7986f6ba54c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T11:48:17.907914Z",
     "start_time": "2024-12-12T11:48:17.535046Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImprovedNaiveBayes(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, smoothing=10**-8):\n",
    "        self.smoothing = smoothing\n",
    "        self.classes_ = None\n",
    "        self.class_probabilities = {}\n",
    "        self.feature_probabilities = {}\n",
    "        self.class_counts = {}\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        for cls in self.classes_:\n",
    "            self.class_probabilities[cls] = np.sum(y == cls) / n_samples\n",
    "            self.class_counts[cls] = np.sum(y == cls)\n",
    "\n",
    "        self.feature_probabilities = {cls: [] for cls in self.classes_}\n",
    "        for cls in self.classes_:\n",
    "            X_cls = X[y == cls]\n",
    "            for feature_idx in range(n_features):\n",
    "                feature_vals = X_cls[:, feature_idx]\n",
    "                unique_vals, counts = np.unique(feature_vals, return_counts=True)\n",
    "                feature_prob = {\n",
    "                    val: count / self.class_counts[cls]\n",
    "                    for val, count in zip(unique_vals, counts)\n",
    "                }\n",
    "                \n",
    "                self.feature_probabilities[cls].append(feature_prob)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        predictions = []\n",
    "        for sample in X:\n",
    "            class_scores = {}\n",
    "            for cls in self.classes_:\n",
    "                score = np.log(self.class_probabilities[cls])\n",
    "                for feature_idx, feature_val in enumerate(sample):\n",
    "                    feature_prob = self.feature_probabilities[cls][feature_idx].get(feature_val, self.smoothing)\n",
    "                    score += np.log(feature_prob)\n",
    "                class_scores[cls] = score\n",
    "            predictions.append(max(class_scores, key=class_scores.get))\n",
    "        \n",
    "        return np.array(predictions)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"smoothing\": self.smoothing}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "        print(f\"Model saved in {filename}.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(filename):\n",
    "        with open(filename, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"Model loaded from {filename}.\")\n",
    "        return model\n",
    "    \n",
    "    def submit(self, X, output_filename=\"predictions.csv\"):\n",
    "        predictions = self.predict(X)\n",
    "        \n",
    "        prediction_df = pd.DataFrame({\n",
    "            'id': range(len(predictions)),\n",
    "            'attack_cat': predictions\n",
    "        })\n",
    "        \n",
    "        prediction_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Predictions saved to {output_filename}.\")\n",
    "        \n",
    "        return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735c725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, test_size=0.3, random_state=42):\n",
    "    X = train_df.drop(['attack_cat', 'label'], axis=1) \n",
    "    y = train_df['attack_cat'] \n",
    "    \n",
    "    numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "    categorical_columns = X.select_dtypes(exclude=['number']).columns\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        X[col] = X[col].fillna(X[col].mode()[0])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    smote = SMOTE(random_state=random_state)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test, scaler, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab7bc96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_data(test_df, scaler, label_encoders):\n",
    "    X_test = test_df.copy()\n",
    "    \n",
    "    numeric_columns = X_test.select_dtypes(include=['number']).columns\n",
    "    categorical_columns = X_test.select_dtypes(exclude=['number']).columns\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        X_test[col] = X_test[col].fillna(X_test[col].median())\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        X_test[col] = X_test[col].fillna(X_test[col].mode()[0])\n",
    "\n",
    "    X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        if col in label_encoders:\n",
    "            le = label_encoders[col]\n",
    "            if 'unknown' not in le.classes_:\n",
    "                le.classes_ = np.append(le.classes_, 'unknown')\n",
    "            \n",
    "            X_test[col] = X_test[col].apply(lambda x: x if x in le.classes_ else 'unknown')\n",
    "            X_test[col] = le.transform(X_test[col])\n",
    "    \n",
    "    return X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aaede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in naive_bayes_model.pkl.\n",
      "Predictions saved to predictions.csv.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(X_train, y_train, model, cv_folds=5):\n",
    "    kfold = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cross_val_scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    \n",
    "    print(f\"\\nCross-Validation Accuracy (Mean): {cross_val_scores.mean() * 100:.2f}%\")\n",
    "    print(f\"Cross-Validation Accuracy (Standard Deviation): {cross_val_scores.std() * 100:.2f}%\")\n",
    "    \n",
    "    return cross_val_scores.mean()\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler, label_encoders = preprocess_data(train_df)\n",
    "\n",
    "nb = ImprovedNaiveBayes()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "nb.save_model('naive_bayes_model.pkl')\n",
    "# prediction_df = nb.submit(X_test, output_filename=\"predictions.csv\")\n",
    "\n",
    "evaluate_model(X_train, y_train, nb, cv_folds=5)\n",
    "\n",
    "predictions = nb.predict(X_test)\n",
    "\n",
    "# nb_sklearn = GaussianNB()\n",
    "# nb_sklearn.fit(X_train, y_train)\n",
    "\n",
    "# evaluate_model(X_train, y_train, nb_sklearn, cv_folds=5)\n",
    "\n",
    "# predictions_sklearn = nb_sklearn.predict(X_test)\n",
    "\n",
    "accuracy_custom = accuracy_score(y_test, predictions)\n",
    "print(f\"\\nNaive Bayes kustom classification accuracy: {accuracy_custom * 100:.2f}%\")\n",
    "print(\"\\nDetailed Classification Report (Custom Naive Bayes):\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# accuracy_sklearn = accuracy_score(y_test, predictions_sklearn)\n",
    "# print(f\"\\nNaive Bayes from sklearn classification accuracy: {accuracy_sklearn * 100:.2f}%\")\n",
    "# print(\"\\nDetailed Classification Report (sklearn Naive Bayes):\")\n",
    "# print(classification_report(y_test, predictions_sklearn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47959d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from naive_bayes_model.pkl.\n",
      "Predictions saved to predictions.csv.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = ImprovedNaiveBayes.load_model('naive_bayes_model.pkl')\n",
    "X_test_processed = preprocess_test_data(test_df, scaler, label_encoders)\n",
    "prediction_df = loaded_model.submit(X_test_processed, output_filename=\"predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
