{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_folder(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    combined_df = df_list[0]\n",
    "    \n",
    "    for df in df_list[1:]:\n",
    "        combined_df = pd.merge(combined_df, df, on='id', how='outer')\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "test_folder = '../data/test/'\n",
    "test_df = load_data_from_folder(test_folder)\n",
    "\n",
    "train_folder = '../data/train/'\n",
    "train_df = load_data_from_folder(train_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, test_size=0.3, random_state=42):\n",
    "    X = train_df.drop(['attack_cat', 'label'], axis=1) \n",
    "    y = train_df['attack_cat'] \n",
    "    \n",
    "    numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "    categorical_columns = X.select_dtypes(exclude=['number']).columns\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        X[col] = X[col].fillna(X[col].mode()[0])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    smote = SMOTE(random_state=random_state)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test, scaler, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_data(test_df, scaler, label_encoders):\n",
    "    X_test = test_df.copy()\n",
    "    \n",
    "    numeric_columns = X_test.select_dtypes(include=['number']).columns\n",
    "    categorical_columns = X_test.select_dtypes(exclude=['number']).columns\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        X_test[col] = X_test[col].fillna(X_test[col].median())\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        X_test[col] = X_test[col].fillna(X_test[col].mode()[0])\n",
    "\n",
    "    X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        if col in label_encoders:\n",
    "            le = label_encoders[col]\n",
    "            if 'unknown' not in le.classes_:\n",
    "                le.classes_ = np.append(le.classes_, 'unknown')\n",
    "            \n",
    "            X_test[col] = X_test[col].apply(lambda x: x if x in le.classes_ else 'unknown')\n",
    "            X_test[col] = le.transform(X_test[col])\n",
    "    \n",
    "    return X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self, k=3, metric=\"euclidean\", weights=\"uniform\", batch_size=1000):\n",
    "        \"\"\"\n",
    "        Initialize the Memory-Efficient KNN Classifier.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        k : int, default=3\n",
    "            Number of neighbors to use\n",
    "        metric : str, default=\"euclidean\"\n",
    "            Distance metric to use\n",
    "        weights : str, default=\"uniform\"\n",
    "            Weight function used in prediction\n",
    "        batch_size : int, default=1000\n",
    "            Number of test points to process in each batch\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.weights = weights\n",
    "        self.batch_size = batch_size\n",
    "        self.train_data = None\n",
    "        self.train_labels = None\n",
    "    \n",
    "    def fit(self, train_data, train_labels):\n",
    "        \"\"\"\n",
    "        Store the training data and labels.\n",
    "        \"\"\"\n",
    "        self.train_data = np.asarray(train_data, dtype=np.float32)\n",
    "        self.train_labels = np.asarray(train_labels)\n",
    "        return self\n",
    "    \n",
    "    def _compute_batch_distances(self, test_batch):\n",
    "        \"\"\"\n",
    "        Compute distances for a batch of test points.\n",
    "        \"\"\"\n",
    "        if self.metric == 'euclidean':\n",
    "            distances = cdist(test_batch, self.train_data, metric='euclidean')\n",
    "        elif self.metric == 'manhattan':\n",
    "            distances = cdist(test_batch, self.train_data, metric='cityblock')\n",
    "        elif self.metric == 'minkowski':\n",
    "            distances = cdist(test_batch, self.train_data, metric='minkowski')\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric: {self.metric}\")\n",
    "        return distances\n",
    "    \n",
    "    def predict(self, test_points):\n",
    "        \"\"\"\n",
    "        Predict labels for test points using batched processing.\n",
    "        \"\"\"\n",
    "        # Validate that model has been trained\n",
    "        if self.train_data is None:\n",
    "            raise ValueError(\"Model has not been trained. Call 'fit' first.\")\n",
    "        \n",
    "        # Convert test points to numpy array\n",
    "        test_points = np.asarray(test_points, dtype=np.float32)\n",
    "        \n",
    "        # Prepare for batched prediction\n",
    "        predictions = []\n",
    "        \n",
    "        # Process test points in batches\n",
    "        for i in range(0, len(test_points), self.batch_size):\n",
    "            # Get current batch\n",
    "            test_batch = test_points[i:i+self.batch_size]\n",
    "            \n",
    "            # Compute distances for current batch\n",
    "            distances = self._compute_batch_distances(test_batch)\n",
    "            \n",
    "            # Predict for each point in the batch\n",
    "            batch_predictions = []\n",
    "            for point_distances in distances:\n",
    "                # Get indices of k nearest neighbors\n",
    "                k_indices = np.argpartition(point_distances, self.k)[:self.k]\n",
    "                \n",
    "                # Get labels of k nearest neighbors\n",
    "                k_labels = self.train_labels[k_indices]\n",
    "                k_dist = point_distances[k_indices]\n",
    "                \n",
    "                # Apply weighting if specified\n",
    "                if self.weights == 'distance':\n",
    "                    # Avoid division by zero\n",
    "                    weights = 1.0 / (k_dist + 1e-8)\n",
    "                    unique_labels, _ = np.unique(k_labels, return_counts=True)\n",
    "                    weighted_votes = []\n",
    "                    for label in unique_labels:\n",
    "                        label_mask = (k_labels == label)\n",
    "                        weighted_vote = np.sum(weights[label_mask])\n",
    "                        weighted_votes.append((label, weighted_vote))\n",
    "                    prediction = max(weighted_votes, key=lambda x: x[1])[0]\n",
    "                else:\n",
    "                    # Uniform weighting (most common label)\n",
    "                    prediction = Counter(k_labels).most_common(1)[0][0]\n",
    "                \n",
    "                batch_predictions.append(prediction)\n",
    "            \n",
    "            # Add batch predictions to overall predictions\n",
    "            predictions.extend(batch_predictions)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Compute the accuracy of the classifier.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X_test)\n",
    "        return np.mean(predictions == y_test)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f\"MemoryEfficientKNNClassifier(k={self.k}, \"\n",
    "                f\"metric='{self.metric}', \"\n",
    "                f\"weights='{self.weights}', \"\n",
    "                f\"batch_size={self.batch_size})\")\n",
    "        \n",
    "    def submit(self, X_test, filename='submission.csv'):\n",
    "        \"\"\"\n",
    "        Make predictions on test data and save them to a CSV file.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X_test)\n",
    "        submission_df = pd.DataFrame({'id': test_df['id'], 'attack_cat': predictions})\n",
    "        submission_df.to_csv(filename, index=False)\n",
    "        return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable, Literal\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_neighbors: int = 3, \n",
    "        distance_metric: Literal['euclidean', 'manhattan', 'minkowski'] = 'euclidean',\n",
    "        p: float = 2  \n",
    "    ):\n",
    "        \"\"\"\n",
    "        K-Nearest Neighbors Classifier implemented from scratch.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_neighbors : int, default=3\n",
    "            Number of neighbors to use for classification\n",
    "        \n",
    "        distance_metric : str, default='euclidean'\n",
    "            Distance metric to use. Options:\n",
    "            - 'euclidean': Euclidean distance\n",
    "            - 'manhattan': Manhattan (city block) distance\n",
    "            - 'minkowski': Minkowski distance (generalization of Euclidean and Manhattan)\n",
    "        \n",
    "        p : float, default=2\n",
    "            Power parameter for Minkowski distance\n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.distance_metric = distance_metric\n",
    "        self.p = p\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "    \n",
    "    def _distance(self, x1: np.ndarray, x2: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate distance between two points based on selected metric.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x1 : numpy array\n",
    "            First data point\n",
    "        x2 : numpy array\n",
    "            Second data point\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            Distance between x1 and x2\n",
    "        \"\"\"\n",
    "        # Validate input shapes\n",
    "        if x1.shape != x2.shape:\n",
    "            raise ValueError(\"Input points must have the same shape\")\n",
    "        \n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((x1 - x2)**2))\n",
    "        \n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(x1 - x2))\n",
    "        \n",
    "        elif self.distance_metric == 'minkowski':\n",
    "            return np.sum(np.abs(x1 - x2)**self.p)**(1/self.p)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported distance metric: {self.distance_metric}\")\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Fit the KNN classifier by storing training data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy array\n",
    "            Training feature data\n",
    "        y : numpy array\n",
    "            Training labels\n",
    "        \"\"\"\n",
    "        # Validate inputs\n",
    "        if X.ndim != 2:\n",
    "            raise ValueError(\"X must be a 2D array\")\n",
    "        \n",
    "        if len(X) != len(y):\n",
    "            raise ValueError(\"X and y must have the same number of samples\")\n",
    "        \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict class labels for input data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy array\n",
    "            Test samples\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy array\n",
    "            Predicted class labels\n",
    "        \"\"\"\n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise ValueError(\"Classifier not fitted. Call fit() first.\")\n",
    "        \n",
    "        # Vectorized prediction for better performance\n",
    "        predictions = np.array([self._predict_single(x) for x in X])\n",
    "        return predictions\n",
    "    \n",
    "    def _predict_single(self, x: np.ndarray):\n",
    "        \"\"\"\n",
    "        Predict class for a single sample.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : numpy array\n",
    "            Single test sample\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        Predicted class label\n",
    "        \"\"\"\n",
    "        # Compute distances to all training points\n",
    "        distances = np.array([self._distance(x, x_train) for x_train in self.X_train])\n",
    "        \n",
    "        print(distances)\n",
    "\n",
    "        # Get indices of k nearest neighbors\n",
    "        k_indices = np.argsort(distances)[:self.n_neighbors]\n",
    "        \n",
    "        # Get the labels of the k nearest neighbors\n",
    "        k_nearest_labels = self.y_train[k_indices]\n",
    "        \n",
    "        # Use majority voting\n",
    "        unique_labels, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "        return unique_labels[np.argmax(counts)]\n",
    "    \n",
    "    def score(self, X_test: np.ndarray, y_test: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the accuracy of the classifier.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_test : numpy array\n",
    "            Test feature data\n",
    "        y_test : numpy array\n",
    "            True labels for test data\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            Accuracy score (0 to 1)\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X_test)\n",
    "        return np.mean(predictions == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# # Train the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# knn = KNNClassifier(k=3, metric=\"euclidean\", weights=\"distance\", batch_size=500)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# knn.fit(X_train, y_train)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# # Evaluate the model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# train_accuracy = knn.score(X_train, y_train)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m X_train, X_test, y_train, y_test, scaler, label_encoders \u001b[38;5;241m=\u001b[39m preprocess_data(train_df)\n\u001b[0;32m----> 9\u001b[0m X_test_processed \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_test_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_encoders\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36mpreprocess_test_data\u001b[0;34m(test_df, scaler, label_encoders)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_columns:\n\u001b[1;32m     11\u001b[0m     X_test[col] \u001b[38;5;241m=\u001b[39m X_test[col]\u001b[38;5;241m.\u001b[39mfillna(X_test[col]\u001b[38;5;241m.\u001b[39mmode()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m X_test[numeric_columns] \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumeric_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_columns:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m label_encoders:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/preprocessing/_data.py:1043\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1040\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1042\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m-> 1043\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n"
     ]
    }
   ],
   "source": [
    "# # Train the model\n",
    "# knn = KNNClassifier(k=3, metric=\"euclidean\", weights=\"distance\", batch_size=500)\n",
    "# knn.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the model\n",
    "# train_accuracy = knn.score(X_train, y_train)\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler, label_encoders = preprocess_data(train_df)\n",
    "X_test_processed = preprocess_test_data(test_df, scaler, label_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array length 52603 does not match index length 20583",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNNClassifier(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m      2\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubmission.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 118\u001b[0m, in \u001b[0;36mKNNClassifier.submit\u001b[1;34m(self, X_est, filename)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03mMake predictions on test data and save them to a CSV file.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m--> 118\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattack_cat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m submission_df\u001b[38;5;241m.\u001b[39mto_csv(filename, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m submission_df\n",
      "File \u001b[1;32mc:\\Users\\preda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:767\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    761\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    762\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    763\u001b[0m     )\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\preda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\preda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\preda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:690\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m    686\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    687\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    688\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    689\u001b[0m         )\n\u001b[1;32m--> 690\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    692\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(lengths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: array length 52603 does not match index length 20583"
     ]
    }
   ],
   "source": [
    "knn = KNNClassifier(k=3, metric=\"euclidean\", weights=\"distance\", batch_size=500)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn.submit(X_test_processed, 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
