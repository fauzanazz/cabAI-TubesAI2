{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15261/4076906630.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].median())\n",
      "/tmp/ipykernel_15261/4076906630.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mode()[0])\n",
      "/tmp/ipykernel_15261/4076906630.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = le.fit_transform(df[col])\n",
      "/tmp/ipykernel_15261/4076906630.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = le.fit_transform(df[col])\n",
      "/tmp/ipykernel_15261/4076906630.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = le.fit_transform(df[col])\n",
      "/tmp/ipykernel_15261/4076906630.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = le.fit_transform(df[col])\n",
      "/tmp/ipykernel_15261/4076906630.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
      "/tmp/ipykernel_15261/4076906630.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].median())\n",
      "/tmp/ipykernel_15261/4076906630.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mode()[0])\n",
      "/tmp/ipykernel_15261/4076906630.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = le.fit_transform(df[col])\n",
      "/tmp/ipykernel_15261/4076906630.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = le.fit_transform(df[col])\n",
      "/tmp/ipykernel_15261/4076906630.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = le.fit_transform(df[col])\n",
      "/tmp/ipykernel_15261/4076906630.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "# Load test data\n",
    "test_folder = '../data/test/'\n",
    "test_files = os.listdir(test_folder)\n",
    "test_df = pd.DataFrame()\n",
    "for file in test_files:\n",
    "    df = pd.read_csv(test_folder + file)\n",
    "    test_df = pd.concat([test_df, df], axis=1)\n",
    "\n",
    "# Load train data\n",
    "train_folder = '../data/train/'\n",
    "train_files = os.listdir(train_folder)\n",
    "train_df = pd.DataFrame()\n",
    "for file in train_files:\n",
    "    df = pd.read_csv(train_folder + file)\n",
    "    train_df = pd.concat([train_df, df], axis=1)\n",
    "\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Drop duplicate columns\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "    # Fill missing values\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "    # Encode categorical columns\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "    # Standardize numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Preprocess train and test data\n",
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_df.drop(['attack_cat', 'label'], axis=1)\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self, k=3, metric=\"euclidean\", weights=\"uniform\", batch_size=1000):\n",
    "        \"\"\"\n",
    "        Initialize the Memory-Efficient KNN Classifier.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        k : int, default=3\n",
    "            Number of neighbors to use\n",
    "        metric : str, default=\"euclidean\"\n",
    "            Distance metric to use\n",
    "        weights : str, default=\"uniform\"\n",
    "            Weight function used in prediction\n",
    "        batch_size : int, default=1000\n",
    "            Number of test points to process in each batch\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.weights = weights\n",
    "        self.batch_size = batch_size\n",
    "        self.train_data = None\n",
    "        self.train_labels = None\n",
    "    \n",
    "    def fit(self, train_data, train_labels):\n",
    "        \"\"\"\n",
    "        Store the training data and labels.\n",
    "        \"\"\"\n",
    "        self.train_data = np.asarray(train_data, dtype=np.float32)\n",
    "        self.train_labels = np.asarray(train_labels)\n",
    "        return self\n",
    "    \n",
    "    def _compute_batch_distances(self, test_batch):\n",
    "        \"\"\"\n",
    "        Compute distances for a batch of test points.\n",
    "        \"\"\"\n",
    "        if self.metric == 'euclidean':\n",
    "            distances = cdist(test_batch, self.train_data, metric='euclidean')\n",
    "        elif self.metric == 'manhattan':\n",
    "            distances = cdist(test_batch, self.train_data, metric='cityblock')\n",
    "        elif self.metric == 'minkowski':\n",
    "            distances = cdist(test_batch, self.train_data, metric='minkowski')\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric: {self.metric}\")\n",
    "        return distances\n",
    "    \n",
    "    def predict(self, test_points):\n",
    "        \"\"\"\n",
    "        Predict labels for test points using batched processing.\n",
    "        \"\"\"\n",
    "        # Validate that model has been trained\n",
    "        if self.train_data is None:\n",
    "            raise ValueError(\"Model has not been trained. Call 'fit' first.\")\n",
    "        \n",
    "        # Convert test points to numpy array\n",
    "        test_points = np.asarray(test_points, dtype=np.float32)\n",
    "        \n",
    "        # Prepare for batched prediction\n",
    "        predictions = []\n",
    "        \n",
    "        # Process test points in batches\n",
    "        for i in range(0, len(test_points), self.batch_size):\n",
    "            # Get current batch\n",
    "            test_batch = test_points[i:i+self.batch_size]\n",
    "            \n",
    "            # Compute distances for current batch\n",
    "            distances = self._compute_batch_distances(test_batch)\n",
    "            \n",
    "            # Predict for each point in the batch\n",
    "            batch_predictions = []\n",
    "            for point_distances in distances:\n",
    "                # Get indices of k nearest neighbors\n",
    "                k_indices = np.argpartition(point_distances, self.k)[:self.k]\n",
    "                \n",
    "                # Get labels of k nearest neighbors\n",
    "                k_labels = self.train_labels[k_indices]\n",
    "                k_dist = point_distances[k_indices]\n",
    "                \n",
    "                # Apply weighting if specified\n",
    "                if self.weights == 'distance':\n",
    "                    # Avoid division by zero\n",
    "                    weights = 1.0 / (k_dist + 1e-8)\n",
    "                    unique_labels, _ = np.unique(k_labels, return_counts=True)\n",
    "                    weighted_votes = []\n",
    "                    for label in unique_labels:\n",
    "                        label_mask = (k_labels == label)\n",
    "                        weighted_vote = np.sum(weights[label_mask])\n",
    "                        weighted_votes.append((label, weighted_vote))\n",
    "                    prediction = max(weighted_votes, key=lambda x: x[1])[0]\n",
    "                else:\n",
    "                    # Uniform weighting (most common label)\n",
    "                    prediction = Counter(k_labels).most_common(1)[0][0]\n",
    "                \n",
    "                batch_predictions.append(prediction)\n",
    "            \n",
    "            # Add batch predictions to overall predictions\n",
    "            predictions.extend(batch_predictions)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Compute the accuracy of the classifier.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X_test)\n",
    "        return np.mean(predictions == y_test)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f\"MemoryEfficientKNNClassifier(k={self.k}, \"\n",
    "                f\"metric='{self.metric}', \"\n",
    "                f\"weights='{self.weights}', \"\n",
    "                f\"batch_size={self.batch_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "knn = KNNClassifier(k=3, metric=\"euclidean\", weights=\"distance\", batch_size=500)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = knn.score(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
