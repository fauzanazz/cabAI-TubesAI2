{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import cdist\n",
    "import scipy.stats as stats\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_folder(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    combined_df = df_list[0]\n",
    "    \n",
    "    for df in df_list[1:]:\n",
    "        combined_df = pd.merge(combined_df, df, on='id', how='outer')\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "test_folder = '../data/test/'\n",
    "test_df = load_data_from_folder(test_folder)\n",
    "\n",
    "train_folder = '../data/train/'\n",
    "train_df = load_data_from_folder(train_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, test_size=0.3, random_state=42):\n",
    "    X = train_df.drop(['attack_cat', 'label'], axis=1) \n",
    "    y = train_df['attack_cat'] \n",
    "    \n",
    "    numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "    categorical_columns = X.select_dtypes(exclude=['number']).columns\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        X[col] = X[col].fillna(X[col].mode()[0])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    smote = SMOTE(random_state=random_state)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test, scaler, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_data(test_df, scaler, label_encoders):\n",
    "    X_test = test_df.copy()\n",
    "    \n",
    "    numeric_columns = X_test.select_dtypes(include=['number']).columns\n",
    "    categorical_columns = X_test.select_dtypes(exclude=['number']).columns\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        X_test[col] = X_test[col].fillna(X_test[col].median())\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        X_test[col] = X_test[col].fillna(X_test[col].mode()[0])\n",
    "\n",
    "    X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        if col in label_encoders:\n",
    "            le = label_encoders[col]\n",
    "            if 'unknown' not in le.classes_:\n",
    "                le.classes_ = np.append(le.classes_, 'unknown')\n",
    "            \n",
    "            X_test[col] = X_test[col].apply(lambda x: x if x in le.classes_ else 'unknown')\n",
    "            X_test[col] = le.transform(X_test[col])\n",
    "    \n",
    "    return X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self, k=3, metric=\"euclidean\", weights=\"uniform\", batch_size=1000):\n",
    "        \"\"\"\n",
    "        Initialize the KNN Classifier.\n",
    "                           \n",
    "        Parameters:\n",
    "        -----------\n",
    "        k : int, default=3\n",
    "            Number of neighbors to use\n",
    "        metric : str, default=\"euclidean\"\n",
    "            Distance metric to use\n",
    "        weights : str, default=\"uniform\"\n",
    "            Weight function used in prediction\n",
    "        batch_size : int, default=1000\n",
    "            Number of test points to process in each batch\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.weights = weights\n",
    "        self.batch_size = batch_size\n",
    "        self.train_data = None\n",
    "        self.train_labels = None\n",
    "    \n",
    "    def fit(self, train_data, train_labels):\n",
    "        \"\"\"\n",
    "        Store the training data and labels.\n",
    "        \"\"\"\n",
    "        self.train_data = np.asarray(train_data, dtype=np.float32)\n",
    "        self.train_labels = np.asarray(train_labels)\n",
    "        return self\n",
    "    \n",
    "    def _compute_batch_distances(self, test_batch):\n",
    "        \"\"\"\n",
    "        Compute distances for a batch of test points.\n",
    "        \"\"\"\n",
    "        if self.metric == 'euclidean':\n",
    "            distances = cdist(test_batch, self.train_data, metric='euclidean')\n",
    "        elif self.metric == 'manhattan':\n",
    "            distances = cdist(test_batch, self.train_data, metric='cityblock')\n",
    "        elif self.metric == 'minkowski':\n",
    "            distances = cdist(test_batch, self.train_data, metric='minkowski')\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric: {self.metric}\")\n",
    "        return distances\n",
    "    \n",
    "    def predict(self, test_points):\n",
    "        \"\"\"\n",
    "        Predict labels for test points.\n",
    "        \"\"\"\n",
    "        if self.train_data is None:\n",
    "            raise ValueError(\"Model has not been trained. Call 'fit' first.\")\n",
    "        \n",
    "        test_points = np.asarray(test_points, dtype=np.float32)\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        # Process test points in batches\n",
    "        for i in range(0, len(test_points), self.batch_size):\n",
    "            \n",
    "            test_batch = test_points[i:i+self.batch_size]\n",
    "            \n",
    "            # Compute distances for current batch\n",
    "            distances = self._compute_batch_distances(test_batch)\n",
    "            \n",
    "            batch_predictions = []\n",
    "            for point_distances in distances:\n",
    "                # Get indices of k nearest neighbors\n",
    "                k_indices = np.argpartition(point_distances, self.k)[:self.k]\n",
    "                \n",
    "                # Get labels of k nearest neighbors\n",
    "                k_labels = self.train_labels[k_indices]\n",
    "                k_dist = point_distances[k_indices]\n",
    "                \n",
    "                if self.weights == 'distance':\n",
    "                    weights = 1.0 / (k_dist + 1e-8)\n",
    "                    unique_labels, _ = np.unique(k_labels, return_counts=True)\n",
    "                    weighted_votes = []\n",
    "                    for label in unique_labels:\n",
    "                        label_mask = (k_labels == label)\n",
    "                        weighted_vote = np.sum(weights[label_mask])\n",
    "                        weighted_votes.append((label, weighted_vote))\n",
    "                    prediction = max(weighted_votes, key=lambda x: x[1])[0]\n",
    "                else:\n",
    "                    # Uniform weighting (most common label)\n",
    "                    prediction = Counter(k_labels).most_common(1)[0][0]\n",
    "                \n",
    "                batch_predictions.append(prediction)\n",
    "            \n",
    "            predictions.extend(batch_predictions)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        predictions = self.predict(X_test)\n",
    "        return np.mean(predictions == y_test)\n",
    "    \n",
    "    def submit(self, X_test, filename='submission.csv'):\n",
    "        predictions = self.predict(X_test)\n",
    "        submission_df = pd.DataFrame({'id': test_df['id'], 'attack_cat': predictions})\n",
    "        submission_df.to_csv(filename, index=False)\n",
    "        return submission_df\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f\"KNNClassifier(k={self.k}, \"\n",
    "                f\"metric='{self.metric}', \"\n",
    "                f\"weights='{self.weights}', \"\n",
    "                f\"batch_size={self.batch_size})\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perbandingan metric dan weights yang digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, scaler, label_encoders = preprocess_data(train_df)\n",
    "\n",
    "for metric in ['euclidean', 'manhattan', 'minkowski']:\n",
    "    for weights in ['uniform', 'distance']:\n",
    "        knn = KNNClassifier(k=3, metric=metric, weights=weights)\n",
    "        knn.fit(X_train, y_train)\n",
    "        print(f\"Metric: {metric}, Weights: {weights}, Accuracy: {knn.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perbandingan dengan library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler, label_encoders = preprocess_data(train_df)\n",
    "\n",
    "knn_lib = KNeighborsClassifier(n_neighbors=3, metric='euclidean', weights='uniform')\n",
    "\n",
    "knn_lib.fit(X_train, y_train)\n",
    "\n",
    "accuracy = knn_lib.score(X_test, y_test)\n",
    "print(f\"Library KNN Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
